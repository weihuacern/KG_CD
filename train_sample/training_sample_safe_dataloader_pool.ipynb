{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "4036f11e-5223-46e5-8948-5cbf70a9bf73",
    "_uuid": "3767d2738682e30c292a466f66bc75fcc80a5076"
   },
   "outputs": [],
   "source": [
    "import os, sys, math, io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import bson\n",
    "import struct\n",
    "from PIL import Image\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4212f62a-86c3-4a13-8882-b4c90f64dac5",
    "_uuid": "8a4bd65c90576d611340e36bce5f49896d942ed1"
   },
   "source": [
    "pytorch Dataloader is not thread safe due to the random access to the bson file on disk and will result in errors if the read if not finished and next read request comes. To use the multiprocessing, instead of putting the indices into the queue, and every worker processes the read bson action simutaneously, the new Dataloader just decode the bson bytes to images and use a pool of workers to transform the images to torch Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "78d8b565-336e-4836-b613-768bb6581499",
    "_uuid": "c43d82c645b098b2dd8fc0962bd392bdfc43057d"
   },
   "outputs": [],
   "source": [
    "class BSONIterator(Dataset):\n",
    "    def __init__(self, bson_file, images_df, offsets_df, transform, train=True):\n",
    "        super(BSONIterator, self).__init__()\n",
    "        self.file = bson_file\n",
    "        self.images_df = images_df\n",
    "        self.offsets_df = offsets_df\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #decode bson bytes to images\n",
    "        image_row = self.images_df.iloc[idx]\n",
    "        product_id = image_row[\"product_id\"]\n",
    "        offset_row = self.offsets_df.loc[product_id]\n",
    "        # Random access this product's data from the BSON file.\n",
    "        self.file.seek(offset_row[\"offset\"])\n",
    "        item_data = self.file.read(offset_row[\"length\"])\n",
    "        item = bson.BSON.decode(item_data)\n",
    "        img_idx = image_row[\"img_idx\"]\n",
    "        return item[\"imgs\"][img_idx][\"picture\"], image_row[\"category_idx\"]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorGenerator():\n",
    "    \n",
    "    def __init__(self, transformer):\n",
    "        self.transformer = transformer\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        #perform the transformation to torch.Tensor\n",
    "        bson_img = data\n",
    "        # Load the image.\n",
    "        image = io.BytesIO(bson_img)\n",
    "        img = Image.open(image)\n",
    "        x = self.transformer(img)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSampler(object):\n",
    "    \"\"\"Wraps another sampler to yield a mini-batch of indices.\n",
    "\n",
    "    Args:\n",
    "        sampler (Sampler): Base sampler.\n",
    "        batch_size (int): Size of mini-batch.\n",
    "        drop_last (bool): If ``True``, the sampler will drop the last batch if\n",
    "            its size would be less than ``batch_size``\n",
    "\n",
    "    Example:\n",
    "        >>> list(BatchSampler(range(10), batch_size=3, drop_last=False))\n",
    "        [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]\n",
    "        >>> list(BatchSampler(range(10), batch_size=3, drop_last=True))\n",
    "        [[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sampler, batch_size, drop_last):\n",
    "        self.sampler = sampler\n",
    "        self.batch_size = batch_size\n",
    "        self.drop_last = drop_last\n",
    "\n",
    "    def __iter__(self):\n",
    "        batch = []\n",
    "        for idx in self.sampler:\n",
    "            batch.append(idx)\n",
    "            if len(batch) == self.batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "        if len(batch) > 0 and not self.drop_last:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.drop_last:\n",
    "            return len(self.sampler) // self.batch_size\n",
    "        else:\n",
    "            return (len(self.sampler) + self.batch_size - 1) // self.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader(object):\n",
    "    \n",
    "    def __init__(self, batch_size, dataset, generator, sampler, pool, train=True, drop_last=False):\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset = dataset\n",
    "        self.generator = generator\n",
    "        self.train = train\n",
    "        self.sampler = sampler\n",
    "        self.batch_sampler = BatchSampler(sampler, batch_size, drop_last)\n",
    "        self.drop_last = drop_last\n",
    "        self.pool = pool\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return DataloaderIter(self)\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    \n",
    "class DataloaderIter(object):\n",
    "    \"Iterates once over the DataLoader's dataset, as specified by the sampler\"\n",
    "\n",
    "    def __init__(self, loader):\n",
    "        self.dataset = loader.dataset\n",
    "        self.generator = loader.generator\n",
    "        self.batch_sampler = loader.batch_sampler\n",
    "        self.sample_iter = iter(self.batch_sampler)\n",
    "        self.pool = loader.pool\n",
    "        self.train = loader.train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_sampler)\n",
    "\n",
    "    def __next__(self):\n",
    "        indices = next(self.sample_iter)  # may raise StopIteration\n",
    "        image_dataset, labels = [], []\n",
    "        for idx in indices:\n",
    "            image_data, label = self.dataset[idx]\n",
    "            image_dataset.append(image_data)\n",
    "            labels.append(label)\n",
    "        #multiprocess the images to torch.Tensor\n",
    "        res = self.pool.map(self.generator, image_dataset)\n",
    "        image_tensor = torch.stack(res, dim=0)\n",
    "        if self.train:\n",
    "            label_tensor = torch.from_numpy(np.array(labels))\n",
    "            return image_tensor, label_tensor\n",
    "        else:\n",
    "            return image_tensor\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_offsets_df = pd.read_csv(\"train_offsets.csv\", index_col=0)\n",
    "train_images_df = pd.read_csv(\"train_images_withlevel.csv\", index_col=0)\n",
    "val_images_df = pd.read_csv(\"val_images_withlevel.csv\", index_col=0)\n",
    "\n",
    "data_dir = \"./input/\"\n",
    "file_dir = r'C:\\Users\\YANG\\Downloads\\cdiscount'\n",
    "train_bson_path = os.path.join(data_dir, \"train_example.bson\")\n",
    "train_bson_file = open(train_bson_path, \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "transformer_train = T.Compose([T.RandomHorizontalFlip(), \n",
    "                             T.ToTensor(),T.Normalize(mean=mean, std=std)])\n",
    "transformer_val = T.Compose([T.ToTensor(),T.Normalize(mean=mean, std=std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes = list(range(96))\n",
    "dataset = BSONIterator(train_bson_file, train_images_df, train_offsets_df, \n",
    "                         transformer_train)\n",
    "train_gen = TensorGenerator(transformer=transformer_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ncore = 4\n",
    "pool = Pool(processes=Ncore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = Dataloader(batch_size=96, dataset=dataset, generator=train_gen, sampler=sampler.RandomSampler(dataset),\n",
    "                          pool=pool, train=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = iter(loader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44 ms, sys: 0 ns, total: 44 ms\n",
      "Wall time: 123 ms\n"
     ]
    }
   ],
   "source": [
    "%time bx, by = next(itr)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test(Ncore):\n",
    "    pool = Pool(processes=Ncore)\n",
    "    loader_train = Dataloader(batch_size=96, dataset=dataset, generator=train_gen, sampler=sampler.RandomSampler(dataset),\n",
    "                          pool=pool, train=True, drop_last=False)\n",
    "    start = time.time()\n",
    "    for i in range(50):\n",
    "        itr = iter(loader_train)\n",
    "        bx, by = next(itr)\n",
    "    end = time.time()\n",
    "    print(bx.size(), by.size())\n",
    "    print((end - start)/50)\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([96, 3, 180, 180]) torch.Size([96])\n",
      "0.12584909915924072\n"
     ]
    }
   ],
   "source": [
    "load_test(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([96, 3, 180, 180]) torch.Size([96])\n",
      "0.08236462593078614\n"
     ]
    }
   ],
   "source": [
    "load_test(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([96, 3, 180, 180]) torch.Size([96])\n",
      "0.06693346500396728\n"
     ]
    }
   ],
   "source": [
    "load_test(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([96, 3, 180, 180]) torch.Size([96])\n",
      "0.06852519989013672\n"
     ]
    }
   ],
   "source": [
    "load_test(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
