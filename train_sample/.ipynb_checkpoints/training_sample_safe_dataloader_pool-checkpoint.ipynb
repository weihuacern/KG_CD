{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "75d61c38-954c-4bd1-a127-5d17e1812402",
    "_uuid": "2ae1f395d8768512da0739dded661e329dbfa14e"
   },
   "source": [
    "This notebook contains a generator class for Keras called `BSONIterator` that can read directly from the BSON data. You can use it in combination with `ImageDataGenerator` for doing data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "4036f11e-5223-46e5-8948-5cbf70a9bf73",
    "_uuid": "3767d2738682e30c292a466f66bc75fcc80a5076"
   },
   "outputs": [],
   "source": [
    "import os, sys, math, io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import bson\n",
    "import struct\n",
    "from PIL import Image\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4212f62a-86c3-4a13-8882-b4c90f64dac5",
    "_uuid": "8a4bd65c90576d611340e36bce5f49896d942ed1"
   },
   "source": [
    "# Part 2: The generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1da50467-d11d-417e-9367-bd8574dfe61a",
    "_uuid": "55331a57195739250c5b530160cf32a57b9a2464"
   },
   "source": [
    "First load the lookup tables from the CSV files (you don't need to do this if you just did all the steps from part 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "17cb7bb4-4941-4d0d-8fa5-2dd60b7014ce",
    "_uuid": "edbb272356d65e3ec9b540bd4597464ae4afa3c5"
   },
   "source": [
    "The Keras generator is implemented by the `BSONIterator` class. It creates batches of images (and their one-hot encoded labels) directly from the BSON file. It can be used with multiple workers.\n",
    "\n",
    "**Note:** For fastest results, put the train.bson and test.bson files on a fast drive (SSD).\n",
    "\n",
    "See also the code in: https://github.com/fchollet/keras/blob/master/keras/preprocessing/image.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "78d8b565-336e-4836-b613-768bb6581499",
    "_uuid": "c43d82c645b098b2dd8fc0962bd392bdfc43057d"
   },
   "outputs": [],
   "source": [
    "class BSONIterator(Dataset):\n",
    "    def __init__(self, bson_file, images_df, offsets_df, transform, train=True):\n",
    "        super(BSONIterator, self).__init__()\n",
    "        self.file = bson_file\n",
    "        self.images_df = images_df\n",
    "        self.offsets_df = offsets_df\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_row = self.images_df.iloc[idx]\n",
    "        product_id = image_row[\"product_id\"]\n",
    "        offset_row = self.offsets_df.loc[product_id]\n",
    "        # Random access this product's data from the BSON file.\n",
    "        self.file.seek(offset_row[\"offset\"])\n",
    "        item_data = self.file.read(offset_row[\"length\"])\n",
    "        item = bson.BSON.decode(item_data)\n",
    "        img_idx = image_row[\"img_idx\"]\n",
    "        return item[\"imgs\"][img_idx][\"picture\"], image_row[\"category_idx\"]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorGenerator():\n",
    "    \n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        bson_img = data\n",
    "        # Load the image.\n",
    "        image = io.BytesIO(bson_img)\n",
    "        img = Image.open(image)\n",
    "        x = self.transform(img)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_offsets_df = pd.read_csv(\"train_offsets.csv\", index_col=0)\n",
    "train_images_df = pd.read_csv(\"train_images.csv\", index_col=0)\n",
    "val_images_df = pd.read_csv(\"val_images.csv\", index_col=0)\n",
    "\n",
    "data_dir = \"./input/\"\n",
    "file_dir = r'C:\\Users\\YANG\\Downloads\\cdiscount'\n",
    "train_bson_path = os.path.join(data_dir, \"train_example.bson\")\n",
    "train_bson_file = open(train_bson_path, \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "transform_train = T.Compose([T.RandomHorizontalFlip(), \n",
    "                             T.ToTensor(),T.Normalize(mean=mean, std=std)])\n",
    "transform_val = T.Compose([T.ToTensor(),T.Normalize(mean=mean, std=std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = list(range(96))\n",
    "train_gen = BSONIterator(train_bson_file, train_images_df, train_offsets_df, \n",
    "                         transform_train)\n",
    "generator = TensorGenerator(transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = io.BytesIO(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer():\n",
    "    def __init__(self, mean, std, train=True):\n",
    "        self.mean = np.array(mean).reshape(3, 1, 1)\n",
    "        self.std = np.array(mean).reshape(3, 1, 1)\n",
    "        self.train = train\n",
    "        \n",
    "    def __call__(self, image):\n",
    "        if self.train:\n",
    "            img = image.transpose(Image.FLIP_LEFT_RIGHT) #flip\n",
    "        else:\n",
    "            img = image\n",
    "        img = np.array(img, np.uint8, copy=False) #grab\n",
    "        img = img.transpose(2, 0, 1) #transpose\n",
    "        img = img/255 #[0, 1]\n",
    "        img = (img-self.mean)/self.std #normalize\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_train = Transformer(mean, std, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 472 ms, sys: 96 ms, total: 568 ms\n",
      "Wall time: 578 ms\n"
     ]
    }
   ],
   "source": [
    "%time imgs = [transformer_train(image) for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 292 ms, sys: 40 ms, total: 332 ms\n",
      "Wall time: 336 ms\n"
     ]
    }
   ],
   "source": [
    "%time imgs_np = np.vstack(imgs).reshape(-1, 3, 180, 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3, 180, 180)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 202 Âµs\n"
     ]
    }
   ],
   "source": [
    "%time imgs_tc = torch.from_numpy(imgs_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 38 ms\n"
     ]
    }
   ],
   "source": [
    "%time imgs2 = [transform_train(image) for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 ms, sys: 0 ns, total: 12 ms\n",
      "Wall time: 12.4 ms\n"
     ]
    }
   ],
   "source": [
    "%time imgs2_tc = torch.stack(imgs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 4.22 ms\n"
     ]
    }
   ],
   "source": [
    "%time imgs2_tc_cuda = imgs2_tc.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ncore = 4\n",
    "pool = Pool(processes=Ncore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    n = 10\n",
    "    start = time.time()\n",
    "#     pool = Pool(processes=Ncore)\n",
    "    for i in range(n):\n",
    "        datasets, labels = [], []\n",
    "        for idx in indexes:\n",
    "            data, label = train_gen[idx]\n",
    "            datasets.append(data)\n",
    "            labels.append(label)\n",
    "        res = pool.map(generator, datasets)\n",
    "    end = time.time()\n",
    "#         pool.close()\n",
    "#         pool.join()\n",
    "    print((end - start)/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time imgs = torch.stack(res, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time imgs_cuda = imgs.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time img_labels = torch.from_numpy(np.array(labels)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
