{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "4036f11e-5223-46e5-8948-5cbf70a9bf73",
    "_uuid": "3767d2738682e30c292a466f66bc75fcc80a5076"
   },
   "outputs": [],
   "source": [
    "import os, sys, math, io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import bson\n",
    "import struct\n",
    "from PIL import Image\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch Dataloader is not thread safe due to the random access to the bson file on disk and will result in errors if the read if not finished and next read request comes. To use the Dataloader, instead of putting the indices into the queue, and every worker processes the read bson action simutaneously, I put read and decoded bson images into the queue, and every worker processes the transform action only. This takes more time in filling the queue but less time in transform the images, while the latter takes more time than the first with a single worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "78d8b565-336e-4836-b613-768bb6581499",
    "_uuid": "c43d82c645b098b2dd8fc0962bd392bdfc43057d"
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, bson_file, images_df, offsets_df, transformer, train=True):\n",
    "        self.file = bson_file\n",
    "        self.images_df = images_df\n",
    "        self.offsets_df = offsets_df\n",
    "        self.transformer = transformer\n",
    "        self.train = train\n",
    "\n",
    "    def __getitem__(self, data):\n",
    "        #Though it has the form of indexing, it is just a function to transform images only.\n",
    "        #This is to conform to the usage of the Dataloader class.\n",
    "        bson_img, y = data\n",
    "        image = io.BytesIO(bson_img)\n",
    "        img = Image.open(image)\n",
    "        x = self.transformer(img)\n",
    "        if self.train:\n",
    "            return x, y\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note the modification in the batchsampler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBatchSampler(object):\n",
    "    \"\"\"Wraps another sampler to yield a mini-batch of indices.\n",
    "\n",
    "    Args:\n",
    "        sampler (Sampler): Base sampler.\n",
    "        batch_size (int): Size of mini-batch.\n",
    "        drop_last (bool): If ``True``, the sampler will drop the last batch if\n",
    "            its size would be less than ``batch_size``\n",
    "\n",
    "    Example:\n",
    "        >>> list(BatchSampler(range(10), batch_size=3, drop_last=False))\n",
    "        [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]\n",
    "        >>> list(BatchSampler(range(10), batch_size=3, drop_last=True))\n",
    "        [[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sampler, batch_size, drop_last):\n",
    "        self.sampler = sampler\n",
    "        self.batch_size = batch_size\n",
    "        self.drop_last = drop_last\n",
    "        self.data_source = sampler.data_source\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #decode the bytes in bson to images here rather than in the Dataset class.\n",
    "        image_row = self.data_source.images_df.iloc[idx]\n",
    "        product_id = image_row[\"product_id\"]\n",
    "        offset_row = self.data_source.offsets_df.loc[product_id]\n",
    "        # Random access this product's data from the BSON file.\n",
    "        self.data_source.file.seek(offset_row[\"offset\"])\n",
    "        item_data = self.data_source.file.read(offset_row[\"length\"])\n",
    "        item = bson.BSON.decode(item_data)\n",
    "        img_idx = image_row[\"img_idx\"]\n",
    "        \n",
    "        return item[\"imgs\"][img_idx][\"picture\"], image_row[\"category_idx\"]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        batch_data = []\n",
    "        for idx in self.sampler:\n",
    "            data = self[idx]\n",
    "            batch_data.append(data)\n",
    "    \n",
    "            if len(batch_data) == self.batch_size:\n",
    "                yield batch_data\n",
    "                batch_data = []\n",
    "        if len(batch_data) > 0 and not self.drop_last:\n",
    "            yield batch_data\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.drop_last:\n",
    "            return len(self.sampler) // self.batch_size\n",
    "        else:\n",
    "            return (len(self.sampler) + self.batch_size - 1) // self.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_offsets_df = pd.read_csv(\"train_offsets.csv\", index_col=0)\n",
    "train_images_df = pd.read_csv(\"train_images_withlevel.csv\", index_col=0)\n",
    "val_images_df = pd.read_csv(\"val_images_withlevel.csv\", index_col=0)\n",
    "\n",
    "data_dir = \"./input/\"\n",
    "train_bson_path = os.path.join(data_dir, \"train_example.bson\")\n",
    "train_bson_file = open(train_bson_path, \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "transformer_train = T.Compose([T.RandomHorizontalFlip(), \n",
    "                             T.ToTensor(),T.Normalize(mean=mean, std=std)])\n",
    "transformer_val = T.Compose([T.ToTensor(),T.Normalize(mean=mean, std=std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Dataset(train_bson_file, train_images_df, train_offsets_df, transformer_train, train=True)\n",
    "batch_size = 96\n",
    "batch_sampler = MyBatchSampler(batch_size=batch_size, sampler=sampler.RandomSampler(dataset_train), drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = DataLoader(dataset=dataset_train, batch_sampler=batch_sampler, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = iter(loader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 41.2 Âµs\n"
     ]
    }
   ],
   "source": [
    "%time bx, by = next(itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([96, 3, 180, 180]) torch.Size([96])\n"
     ]
    }
   ],
   "source": [
    "print(bx.size(), by.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
