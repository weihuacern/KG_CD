{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "4036f11e-5223-46e5-8948-5cbf70a9bf73",
    "_uuid": "3767d2738682e30c292a466f66bc75fcc80a5076"
   },
   "outputs": [],
   "source": [
    "import os, sys, math, io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import bson\n",
    "import struct\n",
    "from PIL import Image\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1da50467-d11d-417e-9367-bd8574dfe61a",
    "_uuid": "55331a57195739250c5b530160cf32a57b9a2464"
   },
   "source": [
    "First load the lookup tables from the CSV files (you don't need to do this if you just did all the steps from part 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "19c24f98-551d-4b95-b8f7-8497ab09eb56",
    "_uuid": "0c0dadb16f6b094748e967e9c682bb18b3b5c336"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bowen/anaconda3/envs/cdiscount/lib/python3.6/site-packages/numpy/lib/arraysetops.py:463: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "train_offsets_df = pd.read_csv(\"train_offsets.csv\", index_col=0)\n",
    "train_images_df = pd.read_csv(\"train_images_all.csv\", index_col=0)\n",
    "val_images_df = pd.read_csv(\"val_images_all.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "78d8b565-336e-4836-b613-768bb6581499",
    "_uuid": "c43d82c645b098b2dd8fc0962bd392bdfc43057d"
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, bson_file, images_df, offsets_df, transformer, train=True):\n",
    "        self.file = bson_file\n",
    "        self.images_df = images_df\n",
    "        self.offsets_df = offsets_df\n",
    "        self.transformer = transformer\n",
    "        self.train = train\n",
    "\n",
    "    def __getitem__(self, data):\n",
    "        bson_img, y = data\n",
    "        image = io.BytesIO(bson_img)\n",
    "        img = Image.open(image)\n",
    "        x = self.transformer(img)\n",
    "        if self.train:\n",
    "            return x, y\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBatchSampler(object):\n",
    "    \"\"\"Wraps another sampler to yield a mini-batch of indices.\n",
    "\n",
    "    Args:\n",
    "        sampler (Sampler): Base sampler.\n",
    "        batch_size (int): Size of mini-batch.\n",
    "        drop_last (bool): If ``True``, the sampler will drop the last batch if\n",
    "            its size would be less than ``batch_size``\n",
    "\n",
    "    Example:\n",
    "        >>> list(BatchSampler(range(10), batch_size=3, drop_last=False))\n",
    "        [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]\n",
    "        >>> list(BatchSampler(range(10), batch_size=3, drop_last=True))\n",
    "        [[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sampler, batch_size, drop_last):\n",
    "        self.sampler = sampler\n",
    "        self.batch_size = batch_size\n",
    "        self.drop_last = drop_last\n",
    "        self.data_source = sampler.data_source\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_row = self.data_source.images_df.iloc[idx]\n",
    "        product_id = image_row[\"product_id\"]\n",
    "        offset_row = self.data_source.offsets_df.loc[product_id]\n",
    "        # Random access this product's data from the BSON file.\n",
    "        self.data_source.file.seek(offset_row[\"offset\"])\n",
    "        item_data = self.data_source.file.read(offset_row[\"length\"])\n",
    "        item = bson.BSON.decode(item_data)\n",
    "        img_idx = image_row[\"img_idx\"]\n",
    "        \n",
    "        return item[\"imgs\"][img_idx][\"picture\"], image_row[\"category_idx\"]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        batch_data = []\n",
    "        for idx in self.sampler:\n",
    "            data = self[idx]\n",
    "            batch_data.append(data)\n",
    "    \n",
    "            if len(batch_data) == self.batch_size:\n",
    "                yield batch_data\n",
    "                batch_data = []\n",
    "        if len(batch_data) > 0 and not self.drop_last:\n",
    "            yield batch_data\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.drop_last:\n",
    "            return len(self.sampler) // self.batch_size\n",
    "        else:\n",
    "            return (len(self.sampler) + self.batch_size - 1) // self.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "86525843-13cc-413e-b372-085e4864a45a",
    "_uuid": "a1de21a39914a95128adb7675b5fa17a5284f338"
   },
   "outputs": [],
   "source": [
    "data_dir = \"./input/\"\n",
    "train_bson_path = os.path.join(data_dir, \"train.bson\")\n",
    "train_bson_file = open(train_bson_path, \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "transformer_train = T.Compose([T.RandomHorizontalFlip(), \n",
    "                             T.ToTensor(),T.Normalize(mean=mean, std=std)])\n",
    "transformer_val = T.Compose([T.ToTensor(),T.Normalize(mean=mean, std=std)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2742b451-159b-4353-a7eb-96885fdf8919",
    "_uuid": "a4a76294778c99600228091e797507026d8ba4c3"
   },
   "source": [
    "Create a generator for training and a generator for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Dataset(train_bson_file, train_images_df, train_offsets_df, transformer_train, train=True)\n",
    "dataset_val = Dataset(train_bson_file, val_images_df, train_offsets_df, transformer_val, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12129141 242152\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_train), len(dataset_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "batch_sampler_train = MyBatchSampler(batch_size=batch_size, sampler=sampler.RandomSampler(dataset_train), \n",
    "                                     drop_last=False)\n",
    "batch_sampler_val = MyBatchSampler(batch_size=batch_size, sampler=sampler.RandomSampler(dataset_val), \n",
    "                                     drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = DataLoader(dataset=dataset_train, batch_sampler=batch_sampler_train, num_workers=4, pin_memory=True)\n",
    "loader_val = DataLoader(dataset=dataset_val, batch_sampler=batch_sampler_val, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47380 946\n"
     ]
    }
   ],
   "source": [
    "print(len(loader_train), len(loader_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5c5871a3-6d4a-4260-b8d4-462454ad8983",
    "_uuid": "c3cb7cadf70e26f22f9cd35f8f375b4e9483325a"
   },
   "source": [
    "## How fast is the generator? Create a single batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = iter(loader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 84 ms, sys: 8 ms, total: 92 ms\n",
      "Wall time: 132 ms\n",
      "torch.Size([256, 3, 180, 180]) torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "%time bx, by = next(itr)\n",
    "print(bx.size(), by.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2250dba6-6ab0-4417-854e-6a3eb924fc33",
    "_uuid": "3daa4847924e17f4bab9a58470460667dc517075"
   },
   "source": [
    "# Part 3: Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ResNet50**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "model.avgpool = nn.AvgPool2d(kernel_size = 6)\n",
    "model.fc = nn.Linear(in_features=2048, out_features=5270) #or 49 + 483 + 5270\n",
    "for layer in [model.conv1, model.bn1, model.relu, model.maxpool, model.layer1, model.layer2, model.layer3]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init.kaiming_normal(model.fc.weight.data)\n",
    "model.fc.bias.data.zero_()\n",
    "model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def adjust_learning_rate(lr, optimizer, epoch, denominator = 2):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = lr * (0.1 ** (epoch // denominator))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.max(dim=1)\n",
    "    correct = pred.eq(target)\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct.float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, print_freq = 500):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    loss_log = []\n",
    "    acc_log = []\n",
    "    \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (img, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        target = target.cuda(async=True)\n",
    "        img = img.cuda(async=True)\n",
    "        img_var = Variable(img)\n",
    "        target_var = Variable(target)\n",
    "\n",
    "        # compute output\n",
    "        output = model(img_var)\n",
    "        loss = criterion(output, target_var)\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(output.data, target, topk=(1, ))[0]#only need top1\n",
    "        losses.update(loss.data[0], img.size(0)) #[0] to take out the float inside torch.Tensor\n",
    "        top1.update(prec1[0], img.size(0))\n",
    "        loss_log.append(losses.val)\n",
    "        acc_log.append(top1.val)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                   epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "#         if i == 10000:\n",
    "#             break\n",
    "    return loss_log, acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, print_freq=50):\n",
    "    batch_time = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (img, target) in enumerate(val_loader):\n",
    "        \n",
    "        target = target.cuda(async=True)\n",
    "        img = img.cuda(async=True)\n",
    "        img_var = Variable(img, volatile=True)\n",
    "        target_var = Variable(target, volatile=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(img_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(output.data, target, topk=(1,))[0]#only need top1\n",
    "        top1.update(prec1[0], img.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, top1=top1))\n",
    "\n",
    "    print(' * Prec@1 {top1.avg:.3f}'.format(top1=top1))\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    best_prec1 = 64\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "    lr = 1e-2\n",
    "    optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr = lr, momentum=0.9, \n",
    "                          weight_decay=0)\n",
    "    resume = None\n",
    "    start_epoch = 0\n",
    "    epochs = 2\n",
    "    arch = 'resnet50'\n",
    "\n",
    "    if resume:\n",
    "        if os.path.isfile(resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(resume))\n",
    "            checkpoint = torch.load(resume)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(resume, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(resume))\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        \n",
    "        adjust_learning_rate(lr=lr, optimizer=optimizer, epoch=epoch, denominator=1)\n",
    "\n",
    "        # train for one epoch\n",
    "        loss_log, acc_log = train(train_loader=loader_train, model=model, criterion=criterion,\n",
    "                                  optimizer=optimizer, epoch=epoch)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader=loader_val, model=model)\n",
    "\n",
    "        # remember best prec@1 and save checkpoint\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': arch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best)\n",
    "\n",
    "        #plot loss and acc\n",
    "        fig = plt.figure(figsize = (6,3), dpi = 1200)\n",
    "        loss_log = np.array(loss_log)\n",
    "        ax1 = plt.subplot(121)\n",
    "        ax1.plot(loss_log)\n",
    "        ax1.set_ylabel('Loss', weight = 'bold')\n",
    "        acc_log = np.array(acc_log)\n",
    "        ax2 = plt.subplot(111)\n",
    "        ax2.plot(acc_log)\n",
    "        ax2.set_ylabel('Train_accuracy', weight = 'bold')\n",
    "        np.savetxt(X=np.vstack((loss_log, acc_log)), fname='loss_acc_log.txt', fmt='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
